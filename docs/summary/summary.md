## 一、机器学习概述

![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131125111.png)

`机器学习(Machine Learning,ML)` 是使用计算机来彰显数据背后的真实含义，它为了把无序的数据转换成有用的信息。是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。
它是人工智能的核心，是使计算机具有智能的根本途径，其应用遍及人工智能的各个领域，**它主要使用归纳、综合而不是演绎。**

## 二、机器学习研究意义

机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能，特别是如何在经验学习中改善具体算法的性能”。 “机器学习是对能通过经验自动改进的计算机算法的研究”。 “机器学习是用数据或以往的经验，以此优化计算机程序的性能标准。” 一种经常引用的英文定义是: A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.

机器学习已应用于多个领域，横跨: 计算机科学、工程技术和统计学等多个学科。有了十分广泛的应用，例如: 数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人运用。

* 搜索引擎: 根据你的搜索点击，优化你下次的搜索结果,是机器学习来帮助搜索引擎判断哪个结果更适合你（也判断哪个广告更适合你）。
* 垃圾邮件: 会自动的过滤垃圾广告邮件到垃圾箱内。
* 超市优惠券: 你会发现，你在购买小孩子尿布的时候，售货员会赠送你一张优惠券可以兑换6罐啤酒。
* 邮局邮寄: 手写软件自动识别寄送贺卡的地址。
* 申请贷款: 通过你最近的金融活动信息进行综合评定，决定你是否合格。

## 三、机器学习使用场景

![image-20210131123426071](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131123426.png)

### 3.1 什么时候机器可以学习？

- 事物存在某种潜在规律
- 某些问题难以使用普通编程解决
- 有大量数据可供使用

### 3.2 最早的机器学习应用

垃圾邮件分辨
传统的计算机解决问题思路：

- 编写规则，定义“垃圾邮件”，让计算机执行
- 对于很多问题，规则很难定义
- 规则在不断变化

### 3.3 机器学习识别动物猫

![image-20210131122750516](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131122757.png)

a. **`模式识别`（官方标准）: 人们通过大量的经验，得到结论，从而判断它就是猫。**

> 模式识别（pattern recognition）: 模式识别是最古老的（作为一个术语而言，可以说是很过时的）。

* 我们把环境与客体统称为“模式”，识别是对模式的一种认知，是如何让一个计算机程序去做一些看起来很“智能”的事情。
* 通过融于智慧和直觉后，通过构建程序，识别一些事物，而不是人，例如: 识别数字。

b. **`机器学习`（数据学习）: 人们通过阅读进行学习，观察它会叫、小眼睛、两只耳朵、四条腿、一条尾巴，得到结论，从而判断它就是猫。**

> 机器学习（machine learning）: 机器学习是最基础的（当下初创公司和研究实验室的热点领域之一）。

* 在90年代初，人们开始意识到一种可以更有效地构建模式识别算法的方法，那就是用数据（可以通过廉价劳动力采集获得）去替换专家（具有很多图像方面知识的人）。
* “机器学习”强调的是，在给计算机程序（或者机器）输入一些数据后，它必须做一些事情，那就是学习这些数据，而这个学习的步骤是明确的。
* 机器学习（Machine Learning）是一门专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身性能的学科。

c. **`深度学习`（深入数据）: 人们通过深入了解它，发现它会'喵喵'的叫、与同类的猫科动物很类似，得到结论，从而判断它就是猫。（深度学习常用领域: 语音识别、图像识别）**

> 深度学习（deep learning）: 深度学习是非常崭新和有影响力的前沿领域，我们甚至不会去思考-后深度学习时代。

* 深度学习是机器学习研究中的一个新的领域，其动机在于建立、模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据，例如图像，声音和文本。

### 3.4 选择算法需要考虑的问题

#### 3.4.1 算法场景

* 预测明天是否下雨，因为可以用历史的天气情况做预测，所以选择监督学习算法
* 给一群陌生的人进行分组，但是我们并没有这些人的类别信息，所以选择无监督学习算法、通过他们身高、体重等特征进行处理。

#### 3.4.2 需要收集或分析的数据是什么

- 举例

![机器学习基础-选择算法](https://gitee.com/zgf1366/pic_store/raw/master/img/20210130213037.jpg)

## 四、机器学习组成

### 4.1 机器学习划分

#### 4.1 按照输入空间划分

- `Concrete Features`
- `Raw Features`
- `Abstract Features`



#### 4.2 按不同协议划分

- `Batch Learning`
- `Online Learning`
- `Active Learning`



#### 4.3 按输出空间划分

![ml_add_1](https://gitee.com/zgf1366/pic_store/raw/master/img/20210130213058.jpg)

- `分类问题`

> 分类（classification）: 将实例数据划分到合适的类别中。

* 说白了就是将一些未知类别的数据分到现在已知的类别中去。比如，根据你的一些信息，判断你是高富帅，还是穷屌丝。
* 评判分类效果好坏的三个指标: 正确率，召回率，F值。
* 应用实例: 判断网站是否被黑客入侵（二分类 ），手写数字的自动识别（多分类）

![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131124958.png)

- 有很过看似不是分类的任务可以转换为分类任务，例如，利用机器学习玩2048游戏，将玩游戏转换为在当前状态下是进行上移、下移、左移还是右移。又比如利用机器学习玩围棋，自动驾驶等等童谣可以转换成分类任务来。

![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131125041.png)



- `回归问题`

> 回归（regression）: 主要用于预测数值型数据。

* 回归问题 —— 对数值型连续随机变量进行预测和建模的监督学习算法。
* 结果是一个连续数字的值，而非一个类别
* 回归往往会通过计算 误差（Error）来确定模型的精确性。
* 应用实例: 股票价格波动的预测，房屋价格的预测等。
* 对于回归任务来说，有些算法只能够解决回归问题；有一些算法只能够解决分类；有一些算法的思路既能够解决回归问题，又能解决分类问题。一些情况下，回归任务可以简化成分类任务。比如，预测学生成绩，我们可能并不需要预测学生的具体成绩而只需要预测学生分数是A、B、C还是D就足够了，那么此时就是一个分类任务。



- `聚类问题`

> 聚类是一种无监督学习任务，该算法基于数据的内部结构寻找观察样本的自然族群（即集群）。

- 聚类问题的标准一般基于距离: 簇内距离（Intra-cluster Distance） 和 簇间距离（Inter-cluster Distance） 。簇内距离是越小越好，也就是簇内的元素越相似越好；而簇间距离越大越好，也就是说簇间（不同簇）元素越不相同越好。
- 一般的，衡量聚类问题会给出一个结合簇内距离和簇间距离的公式。

#### 4.4 按样本标签划分

- `监督式学习（supervised learning）`

> 必须确定目标变量的值，以便机器学习算法可以发现特征和目标变量之间的关系。在监督学习中，给定一组数据，我们知道正确的输出结果应该是什么样子，并且知道在输入和输出之间有着一个特定的关系。 (包括: 分类和回归)

通俗的讲，监督学习就是给机器的训练数据拥有“标记”或者“答案”，例如：

![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131125825.png)

我们需要告诉机器左边的画面是一只狗，而右边的照片是一只猫。同理对于MNIST数据集，给机器图像信息后还应该附上标记信息，如图所示：

![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131125841.png)

- 监督学习常见算法
  - 分类
    - K-近邻算法
    - 决策树
    - 朴素贝叶斯算法
    - 线性回归
    - 局部加权线性回归
    - Ridege回归
    - Lasso最小回归系数估计
    - Logistic回归
    - 支持向量机
    - AdaBoost
  - 回归
    - 线性回归
    - 树回归

* 监督学习需要注意的问题: 
  * 偏置方差权衡
  * 功能的复杂性和数量的训练数据
  * 输入空间的维数
  * 噪声中的输出值
* 知识表示: 
  * 可以采用规则集的形式【例如: 数学成绩大于90分为优秀】
  * 可以采用概率分布的形式【例如: 通过统计分布发现，90%的同学数学成绩，在70分以下，那么大于70分定为优秀】
  * 可以使用训练样本集中的一个实例【例如: 通过样本集合，我们训练出一个模型实例，得出 年轻，数学成绩中高等，谈吐优雅，我们认为是优秀】

- `半监督式学习`

一部分数据有“标记”或者“答案”，另一部分没有

相对监督学习，更常见的是各种原因产生的标记缺失的半监督学习。

通常都先使用无监督学习手段对数据做处理，之后使用监督学习手段作模型的训练和预测。

- `无监督式学习（unsupervised learning）`

> 在机器学习，无监督学习的问题是，在未加标签的数据中，试图找到隐藏的结构。因为提供给学习者的实例是未标记的，因此没有错误或报酬信号来评估潜在的解决方案。
>
> 无监督学习是密切相关的统计数据密度估计的问题。然而无监督学习还包括寻求，总结和解释数据的主要特点等诸多技术。在无监督学习使用的许多方法是基于用于处理数据的数据挖掘方法。
>
> 数据没有类别信息，也不会给定目标值。

通俗的讲，无监督学习就是给机器训练数据没有任何“标记”或者“答案”

![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131125953.png)

* 无监督学习包括的类型: 
  * 聚类: 在无监督学习中，将数据集分成由类似的对象组成多个类的过程称为聚类。
  * 密度估计: 通过样本分布的紧密程度，来估计与分组的相似性。
  * 此外，无监督学习还可以减少数据特征的维度，以便我们可以使用二维或三维图形更加直观地展示数据信息。

- 无监督学习常见算法
  - K-均值聚类
  - 最大期望算法
  - DBSCAN
  - Parzen窗设计
  - 异常检测：如图所示：图中两个红点明显与其他点脱离，如果它们同属与一种数据，我们可以将这两个点归类为异常，将其去除。当突然图中为二维点，在高维中我们会使用相应的算法剔除异常数据。
  
  ![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131130019.png)
- `强化学习`

> 这个算法可以训练程序做出某一决定。程序在某一情况下尝试所有的可能行动，记录不同行动的结果并试着找出最好的一次尝试来做决定。 
>

- 根据周围环境的情况，采取行动，根据采取行动的结果，学习行动方式。

![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131130129.png)

- 强化学习常见算法
  - 马尔可夫决策过程
- 训练过程

![机器学习基础训练过程](https://gitee.com/zgf1366/pic_store/raw/master/img/20210130213001.jpg)

#### 4.5 其他划分

- `在线学习 （Online Learning）`

![image-20210131131012795](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131131012.png)

优点：及时反映新的环境变化
问题：新的数据带来不好的变化？
解决方案：需要加强对数据进行监控
其他：也适用于数据量巨大，完全无法批量学习的环境。

- `批量学习（离线学习）（Batch Learning）`

![image-20210131130751386](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131130751.png)

优点：简单
问题：如何适应环境变化？
解决方案：定时重新批量学习
缺点：每次重新批量学习，运算量巨大；在某些环境变化非常快的情况下，甚至不可能的。

- `参数学习`

![image-20210131131145618](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131131145.png)


$$
f(x)=a^{\star} x+b
$$
在模型学习过程中不断调整 a 和 b

一旦学习到了参数，就不在需要原有的数据集

- `非参数学习`
  - 不对模型进行过多假设
  - 非参数不等于没参数

### 4.2 统计学习三要素

统计学习方法都是由模型、策略、算法构成的，可以简单的理解为

方法=模型+策略+算法

#### 4.2.1 模型（假设空间）

1）

决策函数
$$
F=\left\{f \mid Y=f_{\theta}(X), \theta \in R^{n}\right\}
$$


预测形式
$$
y=f(x)
$$
2）

条件概率分布
$$
F=\left\{P \mid P_{\theta}(Y \mid X), \theta \in R^{n}\right\}
$$


预测形式
$$
\arg \max _{y} P(y \mid x)
$$

#### 4.2.2 策略

即按照什么样的准则学习或选择最优的模型

**损失函数**
$$
L(Y, f(X))=\left\{\begin{array}{l}
1, Y \neq f(X) \\
0, Y=f(X)
\end{array}\right.
$$

$$
L(Y, f(X))=(Y-f(X))^{2}
$$

$$
L(Y, f(X))=|Y-f(X)|
$$

$$
L(Y, P(Y \mid X))-\log P(Y \mid X)
$$

**经验风险最小化**
$$
\min _{f \in F} \frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)
$$
**结构风险最小化**
$$
\min _{f \in F} \frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)+\lambda J(f)
$$

#### 4.2.3 算法

### 4.3 模型评估与模型选择

#### 4.3.1 误差

我们将学习器对样本的实际预测结果与样本的真实值之间的差异成为：误差（error）。定义：	

 - 在训练集上的误差称为`训练误差（training error）`或`经验误差（empirical error）`。
 - 在测试集上的误差称为`测试误差（test error）`。
 - 学习器在所有新样本上的误差称为`泛化误差（generalization error）`。

##### 4.3.1.1 泛化误差上界

泛化误差上界可理解为模型学习能力的“出错上限”，显然，当样本容量趋于无穷大时，泛化误差上界趋于0.

本文介绍较简单的二分类问题中的泛化误差上界.以下先给出结论：

在二分类问题中，若假设空间为有限个函数的集合
$$
\mathcal{F}=\left\{f_{1}, f_{2}, \cdots, f_{d}\right\}
$$
，
对于任意一个函数
$$
f \in \mathcal{F}
$$
，至少以概率1−δ,

以下不等式成立：
$$
R(f) \leqslant \hat{R}(f)+\varepsilon(d, N, \delta)
$$
其中，
$$
R(f)=E[L(Y, f(X))]
$$

$$
\hat{R}(f)=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)
$$

$$
\varepsilon(d, N, \delta)=\sqrt{\frac{1}{2 N}\left(\log d+\log \frac{1}{\delta}\right)}
$$



#### 4.3.2 拟合程度

显然，我们希望得到的是在新样本上表现得很好的学习器，即`泛化误差小`的学习器。因此，我们应该让学习器尽可能地从训练集中学出普适性的“一般特征”，这样在遇到新样本时才能做出正确的判别。然而，当学习器把训练集学得“太好”的时候，即把一些训练样本的自身特点当做了普遍特征；同时也有学习能力不足的情况，即训练集的基本特征都没有学习出来。我们定义：

 - `过拟合（overfitting）`：学习能力过强，以至于把训练样本所包含的不太一般的特性都学到了。
    - 训练误差十分小，但测试误差教大；模型把训练样本学习“太好了”，可能把一些训练样本自身的特性当做了所有潜在样本都有的一般性质，导致泛化能力下降。类比，做课后题全都做对了，超纲题也都认为是考试必考题目，上了考场还是啥都不会。 但过拟合问题还没有十分好的解决方案，过拟合是机器学习面临的关键障碍。

 - `欠拟合（underfitting）`：学习能太差，训练样本的一般性质尚未学好。
    - 训练误差和测试误差都比较大。模型没有很好地捕捉到数据特征，不能够很好地拟合数据，对训练样本的一般性质尚未学好。类比，光看书不做题觉得自己什么都会了，上了考场才知道自己啥都不会。目前，欠拟合问题比较容易克服，例如增加迭代次数等

> 通俗来说，欠拟合和过拟合都可以用一句话来说，欠拟合就是: “你太天真了！”，过拟合就是: “你想太多了！”。

![image-20210131150435347](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131150435.png)

#### 4.3.3 数据集

在现实任务中，我们往往有多种算法可供选择，那么我们应该选择哪一个算法才是最适合的呢？我们希望得到的是泛化误差小的学习器，理想的解决方案是对模型的泛化误差进行评估，然后选择泛化误差最小的那个学习器。但是，泛化误差指的是模型在所有新样本上的适用能力，我们无法直接获得泛化误差。

因此，通常我们采用一个“测试集”来测试学习器对新样本的判别能力，然后以“测试集”上的“测试误差”作为“泛化误差”的近似。显然：我们选取的测试集应尽可能与训练集互斥，下面用一个小故事来解释why：

假设老师出了10 道习题供同学们练习，考试时老师又用同样的这10道题作为试题，可能有的童鞋只会做这10 道题却能得高分，很明显：这个考试成绩并不能有效地反映出真实水平。回到我们的问题上来，我们希望得到泛化性能好的模型，好比希望同学们课程学得好并获得了对所学知识"举一反三"的能力；训练样本相当于给同学们练习的习题，测试过程则相当于考试。显然，若测试样本被用作训练了，则得到的将是过于"乐观"的估计结果。

如上所述：我们希望用一个“测试集”的“测试误差”来作为“泛化误差”的近似，因此我们需要对初始数据集进行有效划分，划分出互斥的“训练集”和“测试集”。

样本集: 训练数据 + 测试数据

* 训练样本 = 特征(feature) + 目标变量(label: 分类-离散值/回归-连续值)
* 特征通常是训练样本集的列，它们是独立测量得到的。
* 目标变量: 目标变量是机器学习预测算法的测试结果。
  * 在分类算法中目标变量的类型通常是标称型(如: 真与假)，而在回归算法中通常是连续型(如: 1~100)。

以[鸢尾花数据集](https://en.wikipedia.org/wiki/lris_flower_data_set)为例： 

![image-20210131124216034](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131124216.png)

下面是鸢尾花的数据：

![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131124233.png)

- 数据整体叫数据集（data set）
- 每一行数据称为一个样本（sample）
- 除最后一列，每一列表达样本的一个特征（feature）
- 最后一列，称为标记（label）

第i个样本行写作![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131124351.png) ，也叫特征向量。第i个样本第j个特征值![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131124406.png) 第i个样本的标记写作![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131124419.png)

为了可视化特征方便，我们只抽取出特征中的前两个特征，其中萼片的长度作为横轴，萼片的宽度作为纵轴。

绘制下图：

![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131124337.png)

对于每一个样本来说都会在坐标系中表示一个点，假设我们有三个特征，就可以在三维空间中表示它，同理如果有1000种特征，就可以在1000维的空间中表示它，而这个绘制样本的空间我们称它为**特征空间(feature space)**。

通过可视化绘制样本点后，我们可以比较轻易的绘制出一根直线，红色样本在直线的一边而蓝色样本在直线的另一边。

**分类任务本质就是在特征空间切分，在高维空间同理。**

而鸢尾花拥有4个特征，应该是在4维特征空间中分析。

> 另外，特征可以很抽象

![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131124736.png)

- 图像，每一个像素点都是特征
- 28*28的图像有28*28=784个特征
- 如果是彩色图像特征更多

##### 4.3.3.1 数据集一般划分

 * `训练集（Training set）` 

   —— 学习样本数据集，通过匹配一些参数来建立一个模型，主要用来训练模型。类比考研前做的解题大全。

 * `验证集（validation set）` 

   —— 对学习出来的模型，调整模型的参数，如在神经网络中选择隐藏单元数。验证集还用来确定网络结构或者控制模型复杂程度的参数。类比 考研之前做的模拟考试。

 * `测试集（Test set）`

   —— 测试训练好的模型的分辨能力。类比 考研。这次真的是一考定终身。

##### 4.3.3.2 留出法

将数据集D划分为两个互斥的集合，一个作为训练集S，一个作为测试集T，满足D=S∪T且S∩T=∅，常见的划分为：大约2/3-4/5的样本用作训练，剩下的用作测试。需要注意的是：训练/测试集的划分要尽可能保持数据分布的一致性，以避免由于分布的差异引入额外的偏差，常见的做法是采取分层抽样。同时，由于划分的随机性，单次的留出法结果往往不够稳定，一般要采用若干次随机划分，重复实验取平均值的做法。

##### 4.3.3.3 交叉验证法

将数据集D划分为k个大小相同的互斥子集，满足D=D1∪D2∪...∪Dk，Di∩Dj=∅（i≠j），同样地尽可能保持数据分布的一致性，即采用分层抽样的方法获得这些子集。交叉验证法的思想是：每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集，这样就有K种训练集/测试集划分的情况，从而可进行k次训练和测试，最终返回k次测试结果的均值。交叉验证法也称“`k折交叉验证`”，k最常用的取值是10，下图给出了10折交叉验证的示意图。

![image-20210131151114643](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131151114.png)

与留出法类似，将数据集D划分为K个子集的过程具有随机性，因此K折交叉验证通常也要重复p次，称为p次k折交叉验证，常见的是10次10折交叉验证，即进行了100次训练/测试。特殊地当划分的k个子集的每个子集中只有一个样本时，称为“留一法”，显然，留一法的评估结果比较准确，但对计算机的消耗也是巨大的。

##### 4.3.3.4 自助法

我们希望评估的是用整个D训练出的模型。但在留出法和交叉验证法中，由于保留了一部分样本用于测试，因此实际评估的模型所使用的训练集比D小，这必然会引入一些因训练样本规模不同而导致的估计偏差。留一法受训练样本规模变化的影响较小，但计算复杂度又太高了。“自助法”正是解决了这样的问题。

自助法的基本思想是：给定包含m个样本的数据集D，每次随机从D 中挑选一个样本，将其拷贝放入D'，然后再将该样本放回初始数据集D 中，使得该样本在下次采样时仍有可能被采到。重复执行m 次，就可以得到了包含m个样本的数据集D'。可以得知在m次采样中，样本始终不被采到的概率取极限为：

$$
\lim _{m \mapsto \infty}\left(1-\frac{1}{m}\right)^{m} \mapsto \frac{1}{e} \approx 0.368
$$
这样，通过自助采样，初始样本集D中大约有36.8%的样本没有出现在D'中，于是可以将D'作为训练集，D-D'作为测试集。自助法在数据集较小，难以有效划分训练集/测试集时很有用，但由于自助法产生的数据集（随机抽样）改变了初始数据集的分布，因此引入了估计偏差。在初始数据集足够时，留出法和交叉验证法更加常用。

#### 4.3.4 调参

大多数学习算法都有些参数(parameter) 需要设定，参数配置不同，学得模型的性能往往有显著差别，这就是通常所说的"参数调节"或简称"调参" (parameter tuning)。

学习算法的很多参数是在实数范围内取值，因此，对每种参数取值都训练出模型来是不可行的。常用的做法是：对每个参数选定一个范围和步长λ，这样使得学习的过程变得可行。例如：假定算法有3 个参数，每个参数仅考虑5 个候选值，这样对每一组训练/测试集就有5*5*5= 125 个模型需考察，由此可见：拿下一个参数（即经验值）对于算法人员来说是有多么的happy。

最后需要注意的是：当选定好模型和调参完成后，我们需要使用初始的数据集D重新训练模型，即让最初划分出来用于评估的测试集也被模型学习，增强模型的学习效果。

### 4.4 性能度量(performance measure)

在上一篇中，我们解决了评估学习器泛化性能的方法，即用测试集的“测试误差”作为“泛化误差”的近似，当我们划分好训练/测试集后，那如何计算“测试误差”呢？这就是性能度量，例如：均方差，错误率等，即“测试误差”的一个评价标准。有了评估方法和性能度量，就可以计算出学习器的“测试误差”，但由于“测试误差”受到很多因素的影响，例如：算法随机性或测试集本身的选择，那如何对两个或多个学习器的性能度量结果做比较呢？这就是比较检验。最后偏差与方差是解释学习器泛化性能的一种重要工具。

性能度量（performance measure）是衡量模型泛化能力的评价标准，在对比不同模型的能力时，使用不同的性能度量往往会导致不同的评判结果。

#### 4.4.1 常见的性能度量

在回归任务中，即预测连续值的问题，最常用的性能度量是“均方误差”（mean squared error）,很多的经典算法都是采用了MSE作为评价函数。
$$
E(f ; D)=\frac{1}{m} \sum_{i=1}^{m}\left(f\left(\boldsymbol{x}_{i}\right)-y_{i}\right)^{2}
$$

$$
\text { 更一般的, 对于数据分布 } \mathcal{D} \text { 和概率密度函数 } p(\cdot), \text { 均方误差可描述为 }
$$

$$
E(f ; \mathcal{D})=\int_{\boldsymbol{x} \sim \mathcal{D}}(f(\boldsymbol{x})-y)^{2} p(\boldsymbol{x}) \mathrm{d} \boldsymbol{x}
$$

在分类任务中，即预测离散值的问题，最常用的是错误率和精度，错误率是分类错误的样本数占样本总数的比例，精度则是分类正确的样本数占样本总数的比例，易知：错误率+精度=1。

错误率定义为
$$
E(f ; D)=\frac{1}{m} \sum_{i=1}^{m} \mathbb{I}\left(f\left(\boldsymbol{x}_{i}\right) \neq y_{i}\right)
$$
精度定义为
$$
\begin{aligned}
\operatorname{acc}(f ; D) &=\frac{1}{m} \sum_{i=1}^{m} \mathbb{I}\left(f\left(\boldsymbol{x}_{i}\right)=y_{i}\right) \\
&=1-E(f ; D)
\end{aligned}
$$
更一般的，对于数据分布D和概率密度函数P（·），错误率和精度可分别描述为
$$
E(f ; \mathcal{D})=\int_{\boldsymbol{x} \sim \mathcal{D}} \mathbb{I}(f(\boldsymbol{x}) \neq y) p(\boldsymbol{x}) \mathrm{d} \boldsymbol{x}
$$


#### 4.4.2 精确率、召回率、F1

错误率和精度虽然常用，但不能满足所有的需求，例如：在推荐系统中，我们只关心推送给用户的内容用户是否感兴趣（即查准率），或者说所有用户感兴趣的内容我们推送出来了多少（即查全率）。因此，使用查准/查全率更适合描述这类问题。对于二分类问题，分类结果混淆矩阵与查准/查全率定义如下：

![image-20210131195245619](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131195245.png)

 * `精确率（precision）` 

   —— 提取出的正确信息条数 / 提取出的信息条数
   $$
   P=\frac{T P}{T P+F P}
   $$
   
 * `召回率（recall）` 

   —— 提取出的正确信息条数 / 样本中的信息条数
   $$
   R=\frac{T P}{T P+F N}
   $$
   
 * `F1值` 

   —— 正确率 * 召回率 * 2 / （正确率 + 召回率）（F值即为正确率和召回率的调和平均值）
   $$
   F 1=\frac{2 \times P \times R}{P+R}=\frac{2 \times T P}{\text { 样例总数 }+T P-T N}
   $$
   ![image-20210131165803863](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131165803.png)

举个例子如下: 
某池塘有 1400 条鲤鱼，300 只虾，300 只乌龟。现在以捕鲤鱼为目的。撒了一张网，逮住了 700 条鲤鱼，200 只
虾， 100 只乌龟。那么这些指标分别如下: 
正确率 = 700 / (700 + 200 + 100) = 70%
召回率 = 700 / 1400 = 50%
F 值 = 70% * 50% * 2 / (70% + 50%) = 58.3%



- 正如天下没有免费的午餐，正确率和召回率是一对矛盾的度量。一般来说，正确率高时，召回率往往偏低;而召回率高时，正确率往往偏低。例如我们想让推送的内容尽可能用户全都感兴趣，那只能推送我们把握高的内容，这样就漏掉了一些用户感兴趣的内容，查全率就低了；如果想让用户感兴趣的内容都被推送，那只有将所有内容都推送上，宁可错杀一千，不可放过一个，这样查准率就很低了。通常只有在一些简单任务中才可能使召回率和正确率都很高。

![image-20210131165552491](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131165552.png)

P-R曲线如何评估呢？若一个学习器A的P-R曲线被另一个学习器B的P-R曲线完全包住，则称：B的性能优于A。若A和B的曲线发生了交叉，则谁的曲线下的面积大，谁的性能更优。但一般来说，曲线下的面积是很难进行估算的，所以衍生出了“平衡点”（Break-Event Point，简称BEP），即当P=R时的取值，平衡点的取值越高，性能更优。

P和R指标有时会出现矛盾的情况，这样就需要综合考虑他们，最常见的方法就是F-Measure，又称F-Score。F-Measure是P和R的加权调和平均。

#### 4.4.3 宏查准率(macro-P)、宏查全率(macro-R)、宏F1

有很多时候我们有多个二分类混淆矩阵，我们希望在n个二分类混淆矩阵上综合考察查准率和查全率。一种直接的做法是先在各混淆矩阵上分别计算出查准率和查全率再计算平均值，这样就得到宏查准率(macro-P)、宏查全率(macro-R),以及相应的宏F1
$$
\operatorname{macro}-P=\frac{1}{n} \sum_{i=1}^{n} P_{i}
$$

$$
\operatorname{macro}-R=\frac{1}{n} \sum_{i=1}^{n} R_{i}
$$

$$
\text { macro- } F 1=\frac{2 \times \operatorname{macro}-P \times \operatorname{macro}-R}{\operatorname{macro}-P+\operatorname{macro}-R}
$$

#### 4.4.4 ROC与AUC

##### 4.4.4.1 ROC曲线

###### 4.4.4.1.1 ROC的动机

　　对于0，1两类分类问题，一些分类器得到的结果往往不是0，1这样的标签，如神经网络得到诸如0.5，0.8这样的分类结果。这时，我们人为取一个阈值，比如0.4，那么小于0.4的归为0类，大于等于0.4的归为1类，可以得到一个分类结果。同样，这个阈值我们可以取0.1或0.2等等。取不同的阈值，最后得到的分类情况也就不同。如下面这幅图：

![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131192339.png)

蓝色表示原始为负类分类得到的统计图，红色表示原始为正类得到的统计图。那么我们取一条直线，直线左边分为负类，直线右边分为正类，这条直线也就是我们所取的阈值。阈值不同，可以得到不同的结果，但是由分类器决定的统计图始终是不变的。这时候就需要一个独立于阈值，只与分类器有关的评价指标，来衡量特定分类器的好坏。还有在类不平衡的情况下，如正样本有90个，负样本有10个，直接把所有样本分类为正样本，得到识别率为90%，但这显然是没有意义的。如上就是ROC曲线的动机。

###### 4.4.4.1.2 ROC的定义

　　关于两类分类问题，原始类为positive、negative，分类后的类别为p'、n'。排列组合后得到4种结果，如下图所示：

![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131192436.png)

　于是我们得到四个指标，分别为：真阳、伪阳、伪阴、真阴。ROC空间将伪阳性率（FPR）定义为 X 轴，真阳性率（TPR）定义为 Y 轴。这两个值由上面四个值计算得到，公式如下：

　　TPR：在所有实际为阳性的样本中，被正确地判断为阳性之比率。TPR=TP/(TP+FN)

　　FPR：在所有实际为阴性的样本中，被错误地判断为阳性之比率。FPR=FP/(FP+TN)

　　放在具体领域来理解上述两个指标。如在医学诊断中，判断有病的样本。那么尽量把有病的揪出来是主要任务，也就是第一个指标TPR，要越高越好。而把没病的样本误诊为有病的，也就是第二个指标FPR，要越低越好。不难发现，这两个指标之间是相互制约的。如果某个医生对于有病的症状比较敏感，稍微的小症状都判断为有病，那么他的第一个指标应该会很高，但是第二个指标也就相应地变高。最极端的情况下，他把所有的样本都看做有病，那么第一个指标达到1，第二个指标也为1。

###### 4.4.4.1.3 ROC的图形化表示

　　我们以FPR为横轴，TPR为纵轴，得到如下ROC空间：

![788753-20161121105420346-41033633](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131192714.png)

我们可以看出：左上角的点（TPR=1，FPR=0），为完美分类，也就是这个医生医术高明，诊断全对；点A（TPR>FPR），医生A的判断大体是正确的。中线上的点B（TPR=FPR），也就是医生B全都是蒙的，蒙对一半，蒙错一半；下半平面的点C（TPR<FPR），这个医生说你有病，那么你很可能没有病，医生C的话我们要反着听，为真庸医。

上图中一个阈值，得到一个点。现在我们需要一个独立于阈值的评价指标来衡量这个医生的医术如何，也就是遍历所有的阈值，得到ROC曲线。还是一开始的那幅图，假设如下就是某个医生的诊断统计图，直线代表阈值。我们遍历所有的阈值，能够在ROC平面上得到如下的ROC曲线。

![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131192803.png)

曲线距离左上角越近，证明分类器效果越好。

![788753-20161121105504034-991875038](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131192908.png)

如上，是三条ROC曲线，在0.23处取一条直线。那么，在同样的FPR=0.23的情况下，红色分类器得到更高的TPR。也就表明，ROC越往上，分类器效果越好。我们用一个标量值AUC来量化他。

##### 4.4.4.2 AUC值

###### 4.4.4.2.1 AUC值的定义

　　AUC值为ROC曲线所覆盖的区域面积，显然，AUC越大，分类器分类效果越好。

　　AUC = 1，是完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器。

　　0.5 < AUC < 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。

　　AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。

　　AUC < 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。

###### 4.4.4.2.2 AUC值的物理意义

　　假设分类器的输出是样本属于正类的socre（置信度），则AUC的物理意义为，任取一对（正、负）样本，正样本的score大于负样本的score的概率。

###### 4.4.4.2.3 AUC值的计算

（1）第一种方法：AUC为ROC曲线下的面积，那我们直接计算面积可得。面积为一个个小的梯形面积之和，计算的精度与阈值的精度有关。

（2）第二种方法：根据AUC的物理意义，我们计算正样本score大于负样本的score的概率。取N*M（N为正样本数，M为负样本数）个二元组，比较score，最后得到AUC。时间复杂度为O(N*M)。

（3）第三种方法：与第二种方法相似，直接计算正样本score大于负样本的score的概率。我们首先把所有样本按照score排序，依次用rank表示他们，如最大score的样本，rank=n(n=N+M)，其次为n-1。那么对于正样本中rank最大的样本（rank_max），有M-1个其他正样本比他score小，那么就有(rank_max-1)-(M-1)个负样本比他score小。其次为(rank_second-1)-(M-2)。最后我们得到正样本大于负样本的概率为：
$$
\frac{\sum_{\text {所有正样本 }} \operatorname{rank}-\mathrm{M}(\mathrm{M}+1) / 2}{M * N}
$$
时间复杂度为O(N+M)。

#### 4.4.5 代价敏感错误率与代价曲线

上面的方法中，将学习器的犯错同等对待，但在现实生活中，将正例预测成假例与将假例预测成正例的代价常常是不一样的，例如：将无疾病-->有疾病只是增多了检查，但有疾病-->无疾病却是增加了生命危险。以二分类为例，由此引入了“代价矩阵”（cost matrix）。

![image-20210131195852432](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131195852.png)

在非均等错误代价下，我们希望的是最小化“总体代价”，这样“代价敏感”的错误率为：
$$
E(f ; D ; c o s t)=\frac{1}{m}\left(\sum_{x_{i} \in D^{+}} \mathbb{I}\left(f\left(x_{i}\right) \neq y_{i}\right) \times \cos t_{01}+\sum_{x_{i} \in D^{-}} \mathbb{I}\left(f\left(x_{i}\right) \neq y_{i}\right) \times \operatorname{cost}_{10}\right)
$$
同样对于ROC曲线，在非均等错误代价下，演变成了“代价曲线”，代价曲线横轴是取值在[0,1]之间的正例概率代价，式中p表示正例的概率，纵轴是取值为[0,1]的归一化代价。
$$
P(+) \cos t=\frac{p \times \operatorname{cost}_{01}}{p \times \operatorname{cost}_{01}+(1-p) \times \operatorname{cost}_{10}}
$$

$$
c o s t_{n o r m}=\frac{F N R \times p \times \cos t_{01}+F P R \times(1-p) \times \operatorname{cost}_{10}}{p \times \cos t_{01}+(1-p) \times \cos t_{10}}
$$

代价曲线的绘制很简单：设ROC曲线上一点的坐标为(TPR，FPR) ，则可相应计算出FNR，然后在代价平面上绘制一条从(0，FPR) 到(1，FNR) 的线段，线段下的面积即表示了该条件下的期望总体代价；如此将ROC 曲线土的每个点转化为代价平面上的一条线段，然后取所有线段的下界，围成的面积即为在所有条件下学习器的期望总体代价，如图所示：

![image-20210131200152578](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131200152.png)

### 4.5 特征工程

 * `特征选择` 

   —— 也叫特征子集选择（FSS，Feature Subset Selection）。是指从已有的 M 个特征（Feature）中选择 N 个特征使得系统的特定指标最优化，是从原始特征中选择出一些最有效特征以降低数据集维度的过程，是提高算法性能的一个重要手段，也是模式识别中关键的数据预处理步骤。

 * `特征提取` 

   —— 特征提取是计算机视觉和图像处理中的一个概念。它指的是使用计算机提取图像信息，决定每个图像的点是否属于一个图像特征。特征提取的结果是把图像上的点分为不同的子集，这些子集往往属于孤立的点，连续的曲线或者连续的区域。

下面给出一个特征工程的图: 

![ml_add_2](https://gitee.com/zgf1366/pic_store/raw/master/img/20210130213112.jpg)

## 五、机器学习开发流程

机器学习不仅仅是调库，但是不反对调库。在调库的时候应该对概念原理了解。

深入代码内部，可以帮助我们更好的理解算法。

更好的理解算法，可以帮助我们更好的选择算法，甚至在将来创造新的算法。

进行机器学习的一般步骤包括以下：

![image-20210131140221351](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131140221.png)

### 5.1 收集数据

- 收集样本数据

### 5.2 准备数据

- 注意数据的格式

### 5.3 分析数据

为了确保数据集中没有垃圾数据；

* 如果是算法可以处理的数据格式或可信任的数据源，则可以跳过该步骤；
* 另外该步骤需要人工干预，会降低自动化系统的价值。

### 5.4 训练算法

[机器学习算法核心]

确定模型的假设空间，即学习的策略

如果使用无监督学习算法，由于不存在目标变量值，则可以跳过该步骤

### 5.5 测试算法

[机器学习算法核心]评估算法效果

### 5.6 使用算法

将机器学习算法转为应用程序，利用学习的最优模型对新数据进行预测或分析

## 六、机器学习数学基础

* 微积分
* 统计学/概率论
* [线性代数](https://nicolas-gaofeng.github.io/Salute_Math/#/linear_algebra/chapter01)

## 七、机器学习工具

### 7.1 Python语言 

1. 可执行伪代码
2. Python比较流行: 使用广泛、代码范例多、丰富模块库，开发周期短
5. Python相关的库
   * 科学函数库: `SciPy`、`NumPy`(底层语言: C和Fortran)
   * 绘图工具库: `Matplotlib`
   * 数据分析库 `Pandas`

### 7.2 数学工具

* Matlab

### 7.3 其他

框架：Scikit-learn

numpy，matplotlib，Jupyter notebook ...

## 八、机器学习哲学思考

### 数据即算法？

机器学习与大数据的结合产生了巨大的价值。基于机器学习技术的发展，数据能够“预测”。对人类而言，积累的经验越丰富，阅历也广泛，对未来的判断越准确。例如常说的“经验丰富”的人比“初出茅庐”的小伙子更有工作上的优势，就在于经验丰富的人获得的规律比他人更准确。而在机器学习领域，根据著名的一个实验，有效的证实了机器学习界一个理论：即机器学习模型的数据越多，机器学习的预测的效率就越好。见下图：

![111](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131132327.png)

通过这张图可以看出，各种不同算法在输入的数据量达到一定级数后，都有相近的高准确度。于是诞生了机器学习界的名言：成功的机器学习应用不是拥有较好的算法，而是拥有最多的数据！

### 算法为王？

![image-20210131132545116](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131132545.png)

alphaGo本身没有太多的数据，而数据都是靠算法产生的，这就说明算法本身也很重要

### 奥卡姆的剃刀

机器学习领域众多的算法如何选择？--简单地就是好的

奥卡姆剃刀原理：一种最基本的归纳偏好，即 “若有多个假设与观察一致，则选最简单那个”。

### 没有免费的午餐定理

**（No Free Lunch Theorem， 简称 NFL 定理）**

算法在训练集之外的所有样本上的误差为：
$$
E_{\text {ote }}\left(\xi_{a} \mid X, f\right)=\sum_{h} \sum_{x \in \chi-X} P(x) \mathbb{I}(h(x) \neq f(x)) P\left(h \mid X, \xi_{a}\right)
$$
对于所有可能的 f 按均匀分布求和，则有：
$$
\begin{aligned}
\sum_{f} E_{\text {ote }}\left(\xi_{a} \mid X, f\right) &=\sum_{f} \sum_{h} \sum_{x \in \chi-X} P(x) \mathbb{I}(h(x) \neq f(x)) P\left(h \mid X, \xi_{a}\right) \\
&=2^{|\chi|-1} \sum_{x \in \chi-X} P(x) \cdot 1
\end{aligned}
$$
可以严格地数学推导出：任意两个算法，总误差与学习算法无关！

也就是说，无论学习算法好坏与否，它们的期望性能都相同！但是我们需要知道上述定理论述过程中假设了 f 的均匀分布，而实际情况可能并非如此。实际运用中，某些假设可能是不符合实际甚至根本不存在的。所以，NFL 定理并非是要让我们认为机器学习算法没有用处，而是要让我们认识到讨论算法要**结合实际**才有意义，脱离实际谈论什么算法更好毫无意义可言。

- 没有一种算法，绝对比另一种算法好
- 脱离具体问题，谈那个算法好是没有意义的
- 在面对一个具体问题的时候，尝试使用多种算法进行对比试验，是必要的。

## 九、机器学习专业术语

* 模型（model）: 计算机层面的认知
* 学习算法（learning algorithm），从数据中产生模型的方法
* 数据集（data set）: 一组记录的合集
* 示例（instance）: 对于某个对象的描述
* 样本（sample）: 也叫示例
* 属性（attribute）: 对象的某方面表现或特征
* 特征（feature）: 同属性
* 属性值（attribute value）: 属性上的取值
* 属性空间（attribute space）: 属性张成的空间
* 样本空间/输入空间（samplespace）: 同属性空间
* 特征向量（feature vector）: 在属性空间里每个点对应一个坐标向量，把一个示例称作特征向量
* 维数（dimensionality）: 描述样本参数的个数（也就是空间是几维的）
* 学习（learning）/训练（training）: 从数据中学得模型
* 训练数据（training data）: 训练过程中用到的数据
* 训练样本（training sample）:训练用到的每个样本
* 训练集（training set）: 训练样本组成的集合
* 假设（hypothesis）: 学习模型对应了关于数据的某种潜在规则
* 真相（ground-truth）:真正存在的潜在规律
* 学习器（learner）: 模型的另一种叫法，把学习算法在给定数据和参数空间的实例化
* 预测（prediction）: 判断一个东西的属性
* 标记（label）: 关于示例的结果信息，比如我是一个“好人”。
* 样例（example）: 拥有标记的示例
* 标记空间/输出空间（label space）: 所有标记的集合
* 分类（classification）: 预测是离散值，比如把人分为好人和坏人之类的学习任务
* 回归（regression）: 预测值是连续值，比如你的好人程度达到了0.9，0.6之类的
* 二分类（binary classification）: 只涉及两个类别的分类任务
* 正类（positive class）: 二分类里的一个
* 反类（negative class）: 二分类里的另外一个
* 多分类（multi-class classification）: 涉及多个类别的分类
* 测试（testing）: 学习到模型之后对样本进行预测的过程
* 测试样本（testing sample）: 被预测的样本
* 聚类（clustering）: 把训练集中的对象分为若干组
* 簇（cluster）: 每一个组叫簇
* 监督学习（supervised learning）: 典范--分类和回归
* 无监督学习（unsupervised learning）: 典范--聚类
* 未见示例（unseen instance）: “新样本“，没训练过的样本
* 泛化（generalization）能力: 学得的模型适用于新样本的能力
* 分布（distribution）: 样本空间的全体样本服从的一种规律
* 独立同分布（independent and identically distributed，简称i,i,d.）:获得的每个样本都是独立地从这个分布上采样获得的。
