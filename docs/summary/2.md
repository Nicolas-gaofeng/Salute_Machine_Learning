## 1. 统计学习三要素

统计学习方法都是由模型、策略、算法构成的，可以简单的理解为

方法=模型+策略+算法

### 1.1 模型（假设空间）

1）决策函数
$$
F=\left\{f \mid Y=f_{\theta}(X), \theta \in R^{n}\right\}
$$


预测形式
$$
y=f(x)
$$
2）条件概率分布
$$
F=\left\{P \mid P_{\theta}(Y \mid X), \theta \in R^{n}\right\}
$$


预测形式
$$
\arg \max _{y} P(y \mid x)
$$

### 1.2 策略

即按照什么样的准则学习或选择最优的模型

**损失函数**
$$
L(Y, f(X))=\left\{\begin{array}{l}
1, Y \neq f(X) \\
0, Y=f(X)
\end{array}\right.
$$

$$
L(Y, f(X))=(Y-f(X))^{2}
$$

$$
L(Y, f(X))=|Y-f(X)|
$$

$$
L(Y, P(Y \mid X))-\log P(Y \mid X)
$$

**经验风险最小化**
$$
\min _{f \in F} \frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)
$$
**结构风险最小化**
$$
\min _{f \in F} \frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)+\lambda J(f)
$$

### 1.3 算法

## 2. 模型评估与模型选择

### 2.1 误差

我们将学习器对样本的实际预测结果与样本的真实值之间的差异成为：误差（error）。定义：	

 - 在训练集上的误差称为`训练误差（training error）`或`经验误差（empirical error）`。
 - 在测试集上的误差称为`测试误差（test error）`。
 - 学习器在所有新样本上的误差称为`泛化误差（generalization error）`。

#### 2.1.1 泛化误差上界

泛化误差上界可理解为模型学习能力的“出错上限”，显然，当样本容量趋于无穷大时，泛化误差上界趋于0.

本文介绍较简单的二分类问题中的泛化误差上界.以下先给出结论：

在二分类问题中，若假设空间为有限个函数的集合
$$
\mathcal{F}=\left\{f_{1}, f_{2}, \cdots, f_{d}\right\}
$$
，
对于任意一个函数
$$
f \in \mathcal{F}
$$
，至少以概率1−δ,

以下不等式成立：
$$
R(f) \leqslant \hat{R}(f)+\varepsilon(d, N, \delta)
$$
其中，
$$
R(f)=E[L(Y, f(X))]
$$

$$
\hat{R}(f)=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)
$$

$$
\varepsilon(d, N, \delta)=\sqrt{\frac{1}{2 N}\left(\log d+\log \frac{1}{\delta}\right)}
$$



### 2.2 拟合程度

显然，我们希望得到的是在新样本上表现得很好的学习器，即`泛化误差小`的学习器。因此，我们应该让学习器尽可能地从训练集中学出普适性的“一般特征”，这样在遇到新样本时才能做出正确的判别。然而，当学习器把训练集学得“太好”的时候，即把一些训练样本的自身特点当做了普遍特征；同时也有学习能力不足的情况，即训练集的基本特征都没有学习出来。我们定义：

 - `过拟合（overfitting）`：学习能力过强，以至于把训练样本所包含的不太一般的特性都学到了。
    - 训练误差十分小，但测试误差教大；模型把训练样本学习“太好了”，可能把一些训练样本自身的特性当做了所有潜在样本都有的一般性质，导致泛化能力下降。类比，做课后题全都做对了，超纲题也都认为是考试必考题目，上了考场还是啥都不会。 但过拟合问题还没有十分好的解决方案，过拟合是机器学习面临的关键障碍。

 - `欠拟合（underfitting）`：学习能太差，训练样本的一般性质尚未学好。
    - 训练误差和测试误差都比较大。模型没有很好地捕捉到数据特征，不能够很好地拟合数据，对训练样本的一般性质尚未学好。类比，光看书不做题觉得自己什么都会了，上了考场才知道自己啥都不会。目前，欠拟合问题比较容易克服，例如增加迭代次数等

> 通俗来说，欠拟合和过拟合都可以用一句话来说，欠拟合就是: “你太天真了！”，过拟合就是: “你想太多了！”。

![image-20210131150435347](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131150435.png)

### 2.3 数据集

在现实任务中，我们往往有多种算法可供选择，那么我们应该选择哪一个算法才是最适合的呢？我们希望得到的是泛化误差小的学习器，理想的解决方案是对模型的泛化误差进行评估，然后选择泛化误差最小的那个学习器。但是，泛化误差指的是模型在所有新样本上的适用能力，我们无法直接获得泛化误差。

因此，通常我们采用一个“测试集”来测试学习器对新样本的判别能力，然后以“测试集”上的“测试误差”作为“泛化误差”的近似。显然：我们选取的测试集应尽可能与训练集互斥，下面用一个小故事来解释why：

假设老师出了10 道习题供同学们练习，考试时老师又用同样的这10道题作为试题，可能有的童鞋只会做这10 道题却能得高分，很明显：这个考试成绩并不能有效地反映出真实水平。回到我们的问题上来，我们希望得到泛化性能好的模型，好比希望同学们课程学得好并获得了对所学知识"举一反三"的能力；训练样本相当于给同学们练习的习题，测试过程则相当于考试。显然，若测试样本被用作训练了，则得到的将是过于"乐观"的估计结果。

如上所述：我们希望用一个“测试集”的“测试误差”来作为“泛化误差”的近似，因此我们需要对初始数据集进行有效划分，划分出互斥的“训练集”和“测试集”。

样本集: 训练数据 + 测试数据

* 训练样本 = 特征(feature) + 目标变量(label: 分类-离散值/回归-连续值)
* 特征通常是训练样本集的列，它们是独立测量得到的。
* 目标变量: 目标变量是机器学习预测算法的测试结果。
  * 在分类算法中目标变量的类型通常是标称型(如: 真与假)，而在回归算法中通常是连续型(如: 1~100)。

以[鸢尾花数据集](https://en.wikipedia.org/wiki/lris_flower_data_set)为例： 

![image-20210131124216034](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131124216.png)

下面是鸢尾花的数据：

![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131124233.png)

- 数据整体叫数据集（data set）
- 每一行数据称为一个样本（sample）
- 除最后一列，每一列表达样本的一个特征（feature）
- 最后一列，称为标记（label）

第i个样本行写作![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131124351.png) ，也叫特征向量。第i个样本第j个特征值![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131124406.png) 第i个样本的标记写作![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131124419.png)

为了可视化特征方便，我们只抽取出特征中的前两个特征，其中萼片的长度作为横轴，萼片的宽度作为纵轴。

绘制下图：

![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131124337.png)

对于每一个样本来说都会在坐标系中表示一个点，假设我们有三个特征，就可以在三维空间中表示它，同理如果有1000种特征，就可以在1000维的空间中表示它，而这个绘制样本的空间我们称它为**特征空间(feature space)**。

通过可视化绘制样本点后，我们可以比较轻易的绘制出一根直线，红色样本在直线的一边而蓝色样本在直线的另一边。

**分类任务本质就是在特征空间切分，在高维空间同理。**

而鸢尾花拥有4个特征，应该是在4维特征空间中分析。

> 另外，特征可以很抽象

![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131124736.png)

- 图像，每一个像素点都是特征
- 28*28的图像有28*28=784个特征
- 如果是彩色图像特征更多

#### 2.3.1 数据集一般划分

 * `训练集（Training set）` 

   —— 学习样本数据集，通过匹配一些参数来建立一个模型，主要用来训练模型。类比考研前做的解题大全。

 * `验证集（validation set）` 

   —— 对学习出来的模型，调整模型的参数，如在神经网络中选择隐藏单元数。验证集还用来确定网络结构或者控制模型复杂程度的参数。类比 考研之前做的模拟考试。

 * `测试集（Test set）`

   —— 测试训练好的模型的分辨能力。类比 考研。这次真的是一考定终身。

#### 2.3.2 留出法

将数据集D划分为两个互斥的集合，一个作为训练集S，一个作为测试集T，满足D=S∪T且S∩T=∅，常见的划分为：大约2/3-4/5的样本用作训练，剩下的用作测试。需要注意的是：训练/测试集的划分要尽可能保持数据分布的一致性，以避免由于分布的差异引入额外的偏差，常见的做法是采取分层抽样。同时，由于划分的随机性，单次的留出法结果往往不够稳定，一般要采用若干次随机划分，重复实验取平均值的做法。

#### 2.3.3 交叉验证法

将数据集D划分为k个大小相同的互斥子集，满足D=D1∪D2∪...∪Dk，Di∩Dj=∅（i≠j），同样地尽可能保持数据分布的一致性，即采用分层抽样的方法获得这些子集。交叉验证法的思想是：每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集，这样就有K种训练集/测试集划分的情况，从而可进行k次训练和测试，最终返回k次测试结果的均值。交叉验证法也称“`k折交叉验证`”，k最常用的取值是10，下图给出了10折交叉验证的示意图。

![image-20210131151114643](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131151114.png)

与留出法类似，将数据集D划分为K个子集的过程具有随机性，因此K折交叉验证通常也要重复p次，称为p次k折交叉验证，常见的是10次10折交叉验证，即进行了100次训练/测试。特殊地当划分的k个子集的每个子集中只有一个样本时，称为“留一法”，显然，留一法的评估结果比较准确，但对计算机的消耗也是巨大的。

#### 2.3.4 自助法

我们希望评估的是用整个D训练出的模型。但在留出法和交叉验证法中，由于保留了一部分样本用于测试，因此实际评估的模型所使用的训练集比D小，这必然会引入一些因训练样本规模不同而导致的估计偏差。留一法受训练样本规模变化的影响较小，但计算复杂度又太高了。“自助法”正是解决了这样的问题。

自助法的基本思想是：给定包含m个样本的数据集D，每次随机从D 中挑选一个样本，将其拷贝放入D'，然后再将该样本放回初始数据集D 中，使得该样本在下次采样时仍有可能被采到。重复执行m 次，就可以得到了包含m个样本的数据集D'。可以得知在m次采样中，样本始终不被采到的概率取极限为：

$$
\lim _{m \mapsto \infty}\left(1-\frac{1}{m}\right)^{m} \mapsto \frac{1}{e} \approx 0.368
$$
这样，通过自助采样，初始样本集D中大约有36.8%的样本没有出现在D'中，于是可以将D'作为训练集，D-D'作为测试集。自助法在数据集较小，难以有效划分训练集/测试集时很有用，但由于自助法产生的数据集（随机抽样）改变了初始数据集的分布，因此引入了估计偏差。在初始数据集足够时，留出法和交叉验证法更加常用。

### 2.4 调参

大多数学习算法都有些参数(parameter) 需要设定，参数配置不同，学得模型的性能往往有显著差别，这就是通常所说的"参数调节"或简称"调参" (parameter tuning)。

学习算法的很多参数是在实数范围内取值，因此，对每种参数取值都训练出模型来是不可行的。常用的做法是：对每个参数选定一个范围和步长λ，这样使得学习的过程变得可行。例如：假定算法有3 个参数，每个参数仅考虑5 个候选值，这样对每一组训练/测试集就有5*5*5= 125 个模型需考察，由此可见：拿下一个参数（即经验值）对于算法人员来说是有多么的happy。

最后需要注意的是：当选定好模型和调参完成后，我们需要使用初始的数据集D重新训练模型，即让最初划分出来用于评估的测试集也被模型学习，增强模型的学习效果。

### 2.5 性能度量(performance measure)

在上一篇中，我们解决了评估学习器泛化性能的方法，即用测试集的“测试误差”作为“泛化误差”的近似，当我们划分好训练/测试集后，那如何计算“测试误差”呢？这就是性能度量，例如：均方差，错误率等，即“测试误差”的一个评价标准。有了评估方法和性能度量，就可以计算出学习器的“测试误差”，但由于“测试误差”受到很多因素的影响，例如：算法随机性或测试集本身的选择，那如何对两个或多个学习器的性能度量结果做比较呢？这就是比较检验。最后偏差与方差是解释学习器泛化性能的一种重要工具。

性能度量（performance measure）是衡量模型泛化能力的评价标准，在对比不同模型的能力时，使用不同的性能度量往往会导致不同的评判结果。

#### 2.5.1 常见的性能度量

在回归任务中，即预测连续值的问题，最常用的性能度量是“均方误差”（mean squared error）,很多的经典算法都是采用了MSE作为评价函数。
$$
E(f ; D)=\frac{1}{m} \sum_{i=1}^{m}\left(f\left(\boldsymbol{x}_{i}\right)-y_{i}\right)^{2}
$$

$$
\text { 更一般的, 对于数据分布 } \mathcal{D} \text { 和概率密度函数 } p(\cdot), \text { 均方误差可描述为 }
$$

$$
E(f ; \mathcal{D})=\int_{\boldsymbol{x} \sim \mathcal{D}}(f(\boldsymbol{x})-y)^{2} p(\boldsymbol{x}) \mathrm{d} \boldsymbol{x}
$$

在分类任务中，即预测离散值的问题，最常用的是错误率和精度，错误率是分类错误的样本数占样本总数的比例，精度则是分类正确的样本数占样本总数的比例，易知：错误率+精度=1。

错误率定义为
$$
E(f ; D)=\frac{1}{m} \sum_{i=1}^{m} \mathbb{I}\left(f\left(\boldsymbol{x}_{i}\right) \neq y_{i}\right)
$$
精度定义为
$$
\begin{aligned}
\operatorname{acc}(f ; D) &=\frac{1}{m} \sum_{i=1}^{m} \mathbb{I}\left(f\left(\boldsymbol{x}_{i}\right)=y_{i}\right) \\
&=1-E(f ; D)
\end{aligned}
$$
更一般的，对于数据分布D和概率密度函数P（·），错误率和精度可分别描述为
$$
E(f ; \mathcal{D})=\int_{\boldsymbol{x} \sim \mathcal{D}} \mathbb{I}(f(\boldsymbol{x}) \neq y) p(\boldsymbol{x}) \mathrm{d} \boldsymbol{x}
$$


#### 2.5.2 精确率、召回率、F1

错误率和精度虽然常用，但不能满足所有的需求，例如：在推荐系统中，我们只关心推送给用户的内容用户是否感兴趣（即查准率），或者说所有用户感兴趣的内容我们推送出来了多少（即查全率）。因此，使用查准/查全率更适合描述这类问题。对于二分类问题，分类结果混淆矩阵与查准/查全率定义如下：

![image-20210131195245619](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131195245.png)

 * `精确率（precision）` 

   —— 提取出的正确信息条数 / 提取出的信息条数
   $$
   P=\frac{T P}{T P+F P}
   $$
   
 * `召回率（recall）` 

   —— 提取出的正确信息条数 / 样本中的信息条数
   $$
   R=\frac{T P}{T P+F N}
   $$
   
 * `F1值` 

   —— 正确率 * 召回率 * 2 / （正确率 + 召回率）（F值即为正确率和召回率的调和平均值）
   $$
   F 1=\frac{2 \times P \times R}{P+R}=\frac{2 \times T P}{\text { 样例总数 }+T P-T N}
   $$
   ![image-20210131165803863](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131165803.png)

举个例子如下: 
某池塘有 1400 条鲤鱼，300 只虾，300 只乌龟。现在以捕鲤鱼为目的。撒了一张网，逮住了 700 条鲤鱼，200 只
虾， 100 只乌龟。那么这些指标分别如下: 
正确率 = 700 / (700 + 200 + 100) = 70%
召回率 = 700 / 1400 = 50%
F 值 = 70% * 50% * 2 / (70% + 50%) = 58.3%



- 正如天下没有免费的午餐，正确率和召回率是一对矛盾的度量。一般来说，正确率高时，召回率往往偏低;而召回率高时，正确率往往偏低。例如我们想让推送的内容尽可能用户全都感兴趣，那只能推送我们把握高的内容，这样就漏掉了一些用户感兴趣的内容，查全率就低了；如果想让用户感兴趣的内容都被推送，那只有将所有内容都推送上，宁可错杀一千，不可放过一个，这样查准率就很低了。通常只有在一些简单任务中才可能使召回率和正确率都很高。

![image-20210131165552491](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131165552.png)

P-R曲线如何评估呢？若一个学习器A的P-R曲线被另一个学习器B的P-R曲线完全包住，则称：B的性能优于A。若A和B的曲线发生了交叉，则谁的曲线下的面积大，谁的性能更优。但一般来说，曲线下的面积是很难进行估算的，所以衍生出了“平衡点”（Break-Event Point，简称BEP），即当P=R时的取值，平衡点的取值越高，性能更优。

P和R指标有时会出现矛盾的情况，这样就需要综合考虑他们，最常见的方法就是F-Measure，又称F-Score。F-Measure是P和R的加权调和平均。

#### 2.5.3 宏查准率(macro-P)、宏查全率(macro-R)、宏F1

有很多时候我们有多个二分类混淆矩阵，我们希望在n个二分类混淆矩阵上综合考察查准率和查全率。一种直接的做法是先在各混淆矩阵上分别计算出查准率和查全率再计算平均值，这样就得到宏查准率(macro-P)、宏查全率(macro-R),以及相应的宏F1
$$
\operatorname{macro}-P=\frac{1}{n} \sum_{i=1}^{n} P_{i}
$$

$$
\operatorname{macro}-R=\frac{1}{n} \sum_{i=1}^{n} R_{i}
$$

$$
\text { macro- } F 1=\frac{2 \times \operatorname{macro}-P \times \operatorname{macro}-R}{\operatorname{macro}-P+\operatorname{macro}-R}
$$

#### 2.5.4 ROC与AUC

##### 2.5.4.1 ROC曲线

###### 2.5.4.1.1 ROC的动机

　　对于0，1两类分类问题，一些分类器得到的结果往往不是0，1这样的标签，如神经网络得到诸如0.5，0.8这样的分类结果。这时，我们人为取一个阈值，比如0.4，那么小于0.4的归为0类，大于等于0.4的归为1类，可以得到一个分类结果。同样，这个阈值我们可以取0.1或0.2等等。取不同的阈值，最后得到的分类情况也就不同。如下面这幅图：

![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131192339.png)

蓝色表示原始为负类分类得到的统计图，红色表示原始为正类得到的统计图。那么我们取一条直线，直线左边分为负类，直线右边分为正类，这条直线也就是我们所取的阈值。阈值不同，可以得到不同的结果，但是由分类器决定的统计图始终是不变的。这时候就需要一个独立于阈值，只与分类器有关的评价指标，来衡量特定分类器的好坏。还有在类不平衡的情况下，如正样本有90个，负样本有10个，直接把所有样本分类为正样本，得到识别率为90%，但这显然是没有意义的。如上就是ROC曲线的动机。

###### 2.5.4.1.2 ROC的定义

　　关于两类分类问题，原始类为positive、negative，分类后的类别为p'、n'。排列组合后得到4种结果，如下图所示：

![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131192436.png)

　于是我们得到四个指标，分别为：真阳、伪阳、伪阴、真阴。ROC空间将伪阳性率（FPR）定义为 X 轴，真阳性率（TPR）定义为 Y 轴。这两个值由上面四个值计算得到，公式如下：

　　TPR：在所有实际为阳性的样本中，被正确地判断为阳性之比率。TPR=TP/(TP+FN)

　　FPR：在所有实际为阴性的样本中，被错误地判断为阳性之比率。FPR=FP/(FP+TN)

　　放在具体领域来理解上述两个指标。如在医学诊断中，判断有病的样本。那么尽量把有病的揪出来是主要任务，也就是第一个指标TPR，要越高越好。而把没病的样本误诊为有病的，也就是第二个指标FPR，要越低越好。不难发现，这两个指标之间是相互制约的。如果某个医生对于有病的症状比较敏感，稍微的小症状都判断为有病，那么他的第一个指标应该会很高，但是第二个指标也就相应地变高。最极端的情况下，他把所有的样本都看做有病，那么第一个指标达到1，第二个指标也为1。

###### 2.5.4.1.3 ROC的图形化表示

　　我们以FPR为横轴，TPR为纵轴，得到如下ROC空间：

![788753-20161121105420346-41033633](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131192714.png)

我们可以看出：左上角的点（TPR=1，FPR=0），为完美分类，也就是这个医生医术高明，诊断全对；点A（TPR>FPR），医生A的判断大体是正确的。中线上的点B（TPR=FPR），也就是医生B全都是蒙的，蒙对一半，蒙错一半；下半平面的点C（TPR<FPR），这个医生说你有病，那么你很可能没有病，医生C的话我们要反着听，为真庸医。

上图中一个阈值，得到一个点。现在我们需要一个独立于阈值的评价指标来衡量这个医生的医术如何，也就是遍历所有的阈值，得到ROC曲线。还是一开始的那幅图，假设如下就是某个医生的诊断统计图，直线代表阈值。我们遍历所有的阈值，能够在ROC平面上得到如下的ROC曲线。

![img](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131192803.png)

曲线距离左上角越近，证明分类器效果越好。

![788753-20161121105504034-991875038](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131192908.png)

如上，是三条ROC曲线，在0.23处取一条直线。那么，在同样的FPR=0.23的情况下，红色分类器得到更高的TPR。也就表明，ROC越往上，分类器效果越好。我们用一个标量值AUC来量化他。

##### 2.5.4.2 AUC值

###### 2.5.4.2.1 AUC值的定义

　　AUC值为ROC曲线所覆盖的区域面积，显然，AUC越大，分类器分类效果越好。

　　AUC = 1，是完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器。

　　0.5 < AUC < 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。

　　AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。

　　AUC < 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。

###### 2.5.4.2.2 AUC值的物理意义

　　假设分类器的输出是样本属于正类的socre（置信度），则AUC的物理意义为，任取一对（正、负）样本，正样本的score大于负样本的score的概率。

###### 2.5.4.2.3 AUC值的计算

（1）第一种方法：AUC为ROC曲线下的面积，那我们直接计算面积可得。面积为一个个小的梯形面积之和，计算的精度与阈值的精度有关。

（2）第二种方法：根据AUC的物理意义，我们计算正样本score大于负样本的score的概率。取N*M（N为正样本数，M为负样本数）个二元组，比较score，最后得到AUC。时间复杂度为O(N*M)。

（3）第三种方法：与第二种方法相似，直接计算正样本score大于负样本的score的概率。我们首先把所有样本按照score排序，依次用rank表示他们，如最大score的样本，rank=n(n=N+M)，其次为n-1。那么对于正样本中rank最大的样本（rank_max），有M-1个其他正样本比他score小，那么就有(rank_max-1)-(M-1)个负样本比他score小。其次为(rank_second-1)-(M-2)。最后我们得到正样本大于负样本的概率为：
$$
\frac{\sum_{\text {所有正样本 }} \operatorname{rank}-\mathrm{M}(\mathrm{M}+1) / 2}{M * N}
$$
时间复杂度为O(N+M)。

#### 2.5.5 代价敏感错误率与代价曲线

上面的方法中，将学习器的犯错同等对待，但在现实生活中，将正例预测成假例与将假例预测成正例的代价常常是不一样的，例如：将无疾病-->有疾病只是增多了检查，但有疾病-->无疾病却是增加了生命危险。以二分类为例，由此引入了“代价矩阵”（cost matrix）。

![image-20210131195852432](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131195852.png)

在非均等错误代价下，我们希望的是最小化“总体代价”，这样“代价敏感”的错误率为：
$$
E(f ; D ; c o s t)=\frac{1}{m}\left(\sum_{x_{i} \in D^{+}} \mathbb{I}\left(f\left(x_{i}\right) \neq y_{i}\right) \times \cos t_{01}+\sum_{x_{i} \in D^{-}} \mathbb{I}\left(f\left(x_{i}\right) \neq y_{i}\right) \times \operatorname{cost}_{10}\right)
$$
同样对于ROC曲线，在非均等错误代价下，演变成了“代价曲线”，代价曲线横轴是取值在[0,1]之间的正例概率代价，式中p表示正例的概率，纵轴是取值为[0,1]的归一化代价。
$$
P(+) \cos t=\frac{p \times \operatorname{cost}_{01}}{p \times \operatorname{cost}_{01}+(1-p) \times \operatorname{cost}_{10}}
$$

$$
c o s t_{n o r m}=\frac{F N R \times p \times \cos t_{01}+F P R \times(1-p) \times \operatorname{cost}_{10}}{p \times \cos t_{01}+(1-p) \times \cos t_{10}}
$$

代价曲线的绘制很简单：设ROC曲线上一点的坐标为(TPR，FPR) ，则可相应计算出FNR，然后在代价平面上绘制一条从(0，FPR) 到(1，FNR) 的线段，线段下的面积即表示了该条件下的期望总体代价；如此将ROC 曲线土的每个点转化为代价平面上的一条线段，然后取所有线段的下界，围成的面积即为在所有条件下学习器的期望总体代价，如图所示：

![image-20210131200152578](https://gitee.com/zgf1366/pic_store/raw/master/img/20210131200152.png)

### 2.6 比较检验

由于“测试误差”受到很多因素的影响，例如：算法随机性(例如常见的K-Means)或测试集本身的选择，使得同一模型每次得到的结果不尽相同，同时测试误差是作为泛化误差的近似，并不能代表学习器真实的泛化性能，那如何对单个或多个学习器在不同或相同测试集上的性能度量结果做比较呢？这就是比较检验。

在比较学习器泛化性能的过程中，统计假设检验（hypothesis test）为学习器性能比较提供了重要依据，即若A在某测试集上的性能优于B，那A学习器比B好的把握有多大。 为方便论述，本篇中都是以“错误率”作为性能度量的标准。

#### 2.6.1 假设检验

“假设”指的是对样本总体的分布或已知分布中某个参数值的一种猜想，例如：假设总体服从泊松分布，或假设正态总体的期望u=u0。回到本篇中，我们可以通过测试获得测试错误率，但直观上测试错误率和泛化错误率相差不会太远，因此可以通过测试错误率来推测泛化错误率的分布，这就是一种假设检验。

![1.png](https://gitee.com/zgf1366/pic_store/raw/master/img/20210208185741.png)

![2.png](https://gitee.com/zgf1366/pic_store/raw/master/img/20210208185751.png)

![3.png](https://gitee.com/zgf1366/pic_store/raw/master/img/20210208185759.png)

#### 2.6.2 交叉验证t检验

![4.png](https://gitee.com/zgf1366/pic_store/raw/master/img/20210208185823.png)

#### 2.6.3 McNemar检验

MaNemar主要用于二分类问题，与成对t检验一样也是用于比较两个学习器的性能大小。主要思想是：若两学习器的性能相同，则A预测正确B预测错误数应等于B预测错误A预测正确数，即e01=e10，且|e01-e10|服从N（1，e01+e10）分布。

![5.png](https://gitee.com/zgf1366/pic_store/raw/master/img/20210208185844.png)

因此，如下所示的变量服从自由度为1的卡方分布，即服从标准正态分布N（0,1）的随机变量的平方和，下式只有一个变量，故自由度为1，检验的方法同上：做出假设-->求出满足显著度的临界点-->给出拒绝域-->验证假设。

![6.png](https://gitee.com/zgf1366/pic_store/raw/master/img/20210208185858.png)

#### 2.6.4 Friedman检验与Nemenyi后续检验

上述的三种检验都只能在一组数据集上，F检验则可以在多组数据集进行多个学习器性能的比较，基本思想是在同一组数据集上，根据测试结果（例：测试错误率）对学习器的性能进行排序，赋予序值1,2,3...，相同则平分序值，如下图所示：

![7.png](https://gitee.com/zgf1366/pic_store/raw/master/img/20210208185919.png)

若学习器的性能相同，则它们的平均序值应该相同，且第i个算法的平均序值ri服从正态分布N（（k+1）/2，（k+1）(k-1)/12），则有：

![8.png](https://gitee.com/zgf1366/pic_store/raw/master/img/20210208185930.png)



![9.png](https://gitee.com/zgf1366/pic_store/raw/master/img/20210208185936.png)

服从自由度为k-1和(k-1)(N-1)的F分布。下面是F检验常用的临界值：

![10.png](https://gitee.com/zgf1366/pic_store/raw/master/img/20210208185950.png)

若“H0：所有算法的性能相同”这个假设被拒绝，则需要进行后续检验，来得到具体的算法之间的差异。常用的就是Nemenyi后续检验。Nemenyi检验计算出平均序值差别的临界值域，下表是常用的qa值，若两个算法的平均序值差超出了临界值域CD，则相应的置信度1-α拒绝“两个算法性能相同”的假设。

![11.png](https://gitee.com/zgf1366/pic_store/raw/master/img/20210208190002.png)

![12.png](https://gitee.com/zgf1366/pic_store/raw/master/img/20210208190006.png)

### 2.7 偏差与方差

偏差-方差分解是解释学习器泛化性能的重要工具。

- 偏差：

期望值与真实值之间的一致差距，衡量的是学习器预测的**准确性**

- 方差:

期望值与真实值之间的波动程度，衡量的是学习器预测的**稳定性**

通过对泛化误差的进行分解，可以得到：

 + **期望泛化误差=方差+偏差**	
 + **偏差刻画学习器的拟合能力**
 + **方差体现学习器的稳定性**

易知：方差和偏差具有矛盾性，这就是常说的偏差-方差窘境（bias-variance dilamma），随着训练程度的提升，期望预测值与真实值之间的差异越来越小，即偏差越来越小，但是另一方面，随着训练程度加大，学习算法对数据集的波动越来越敏感，方差值越来越大。换句话说：在欠拟合时，偏差主导泛化误差，而训练到一定程度后，偏差越来越小，方差主导了泛化误差。因此训练也不要贪杯，适度辄止。

![13.png](https://gitee.com/zgf1366/pic_store/raw/master/img/20210208190033.png)

#### 2.7.1 高方差

什么情况下引发高方差？

- 过高复杂度的模型，对训练集进行过拟合
  - 带来的后果就是在训练集合上效果非常好，但是在校验集合上效果极差
  - 更加形象的理解就是用一条高次方程去拟合线性数据

如何解决高方差问题？

- 在模型复杂程度不变的情况下，增加更多数据
- 在数据量不变的情况下，减少特征维度
- 在数据和模型都不变的情况下，加入正则化

以上方法是否一定有效？

- 增加数据如果和原数据分布一致，无论增加多少必定解决不了高方差
  - smote对样本进行扩充是否必定可以避免高方差？
  - 过采样是否解决高方差问题？
- 减少的特征维度如果是共线性的维度，对原模型没有任何影响
  - 罗辑回归中，如果把一列特征重复2遍，会对最后的结果产生影响么？
- 正则化通常都是有效的

#### 2.7.2 高偏差

如何解决高偏差问题？

- 尝试获得更多的特征
  - 从数据入手，进行特征交叉，或者特征的embedding化
- 尝试增加多项式特征
  - 从模型入手，增加更多线性及非线性变化，提高模型的复杂度
- 尝试减少正则化程度λ

以上方法是否一定有效？

- 特征越稀疏，高方差的风险越高
- 多个线性变换=一个线性变换，多个非线性变换不一定=一个多线性变换
- 正则化通常都是有效的

#### 2.7.3 模型训练为什么要引入偏差和方差？

优化监督学习=优化模型的泛化误差，模型的泛化误差可分解为偏差、方差与噪声之和
**Err = bias + var + irreducible error** 

以回归任务为例,其实更准确的公式为：**Err = bias^2 + var + irreducible error^2** 

符号的定义：一个真实的任务可以理解为Y=f(x)+e，其中f(x)为规律部分，e为噪声部分

#### 2.7.4 Bagging、Boosting的方差偏差问题

- 从偏差-方差分解的角度看，Bagging主要关注降低方差，因此它在不剪枝决策树，神经网络等易受样本扰动的学习器上效果更为明显。
- 从偏差-方差分解的角度看，Boosting主要关注降低偏差，因此Boosting能基于泛化性能相当弱的学习器构建出很强的集成。

- - bagging和boosting都要n个模型，假设基模型权重![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8lyh07lb3j300a00c0ok.jpg)，相关系数![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8lyi3r97uj300900c0oe.jpg)，方差![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8lzqhhkfwj300h00g0rq.jpg)均相等
  - Var(x,y) = Var(x) + Var(y) + 2Cov(x,y)
- Bagging
  - Var(F) = ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8lyk4wjxkj302v00qa9u.jpg)
        = ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8lyp35ynkj308l00qglh.jpg)
    - 其中
      - ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8lypqw1tjj300d00c0q9.jpg)可以直接提取出来
      - ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8lyuaep07j308v00ya9x.jpg)
    - 所以，化简以上的式子可得：Var(F) = m * ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8lyw59y9oj300h00g0rq.jpg) * ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8lywg4870j300g00k0r2.jpg) + ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8lyzygc4lj304300lgle.jpg)
    - 以上为通式，对于bagging来说，每个基模型的权重等于1/m且期望近似相等，所以![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8lz1clt7wj301g011gld.jpg)，带入即可
    - Var(F) = ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8lz7qrpwsj304f015t8i.jpg)
    - E(F) = ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8lz97enuuj3059011743.jpg)
  - 结论：
    - 整体模型的期望近似于基模型的期望，这也就意味着整体模型的偏差和基模型的偏差近似
    - 整体模型的方差小于等于基模型的方差（当相关性为1时取等号），随着基模型数（m）的增多，整体模型的方差减少，从而防止过拟合的能力增强，模型的准确度得到提高
    - bagging的防止过拟合的极限在1/m项趋近于0，所以并不是可以无穷的降低方差达到提高模型准确性的效果的

- Boosting 同理
  - boosting的前提是弱模型之间高度相关，我们不妨设相关度为1
  - Var(F) = ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8lzwvy93dj302k00kmwx.jpg)
  - ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8lzj06hv1j304300qwea.jpg)
  - 结论：
    - 整体模型的期望近似于基模型的期望之和，模型越多期望越容易拟合真实值
    - 整体模型的方差等于基模型的数量平方成正比，越多模型不稳定性越高，越容易过拟合。
    - Gradient Boosting Decision Tree为典型例子

## 3. 特征工程

![ml_add_2](https://gitee.com/zgf1366/pic_store/raw/master/img/20210208163110.jpeg)

特征工程是将原始数据转换为更好地代表预测模型的潜在问题的特征的过程，从而提高了对未知数据的模型准确性

 * `特征选择` 

   —— 也叫特征子集选择（FSS，Feature Subset Selection）。是指从已有的 M 个特征（Feature）中选择 N 个特征使得系统的特定指标最优化，是从原始特征中选择出一些最有效特征以降低数据集维度的过程，是提高算法性能的一个重要手段，也是模式识别中关键的数据预处理步骤。

 * `特征提取` 

   —— 特征提取是计算机视觉和图像处理中的一个概念。它指的是使用计算机提取图像信息，决定每个图像的点是否属于一个图像特征。特征提取的结果是把图像上的点分为不同的子集，这些子集往往属于孤立的点，连续的曲线或者连续的区域。

   `注：特征值化是为了计算机更好的去理解数据`

### 3.1 特征抽取

sklearn特征抽取API

-  sklearn.feature_extraction

**连续特征常用方法**

- 截断
    - 连续型的数值进行截断或者对长尾数据进行对数后截断(保留重要信息的前提下对特征进行截断,截断后的特征也可以看作是类别特征)
    - 参考异常点里面的outlier识别，以最大值填充或者以None
- 二值化
    - 数据分布过于不平衡
    - 空值/异常值过多
- 分桶
    - 小范围连续数据内不存在逻辑关系，比如31岁和32岁之间不存在明显的差异，可以归为一类
    - ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8n2hcomdwj30k60djdh4.jpg)
- 离散化    
    - 数值无意义，比如学历、祖籍等等
- 缩放
    - z-score标准化
    - min-max归一化
    - 范数归一化:![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8mf5xdj2sj3031011jr6.jpg)
        - L1范数
        - L2范数
    - 平方根缩放
    - 对数缩放
        - 对数缩放适用于处理长尾分且取值为正数的数值变量
            - 它将大端长尾压缩为短尾，并将小端进行延伸
        - 可以把类似较差的特征线性化，比如x1x2/y，log变换后变成了log(x1)+log(x2)-log(y)
        - 可以把有偏分布修正为近似正太分布
    - Box-Cox转换
        - ![](https://tva1.sinaimg.cn/large/006y8mN6ly1g8mfjjwir3j309m038gln.jpg)
        - 通过因变量的变换，使得变换后的y(λ)与自变量具有线性依托关系。因此，Box-Cox变换是通过参数的适当选择，达到对原来数据的“综合治理”，使其满足一个线性模型条件
- 特征交叉
    - 人为分段交叉
        - 提升模型的拟合能力，使基向量更有表示能力。比如，本来是在二维空间解释一个点的意义，现在升维到三维后解释
        - 离散变量的交并补
        - 连续变量的点积，attention类似
        - 交叉中需要并行特征筛选的步骤
            - ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8n2rf5aawj30ka0j6q48.jpg)
    - 自动组合
        - FM/FFM中的矩阵点积
            - ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8n2un2ckzj30eb07jaan.jpg)
        - Neural Network里面的dense
            - ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8n2vb1nnij30co07lt94.jpg)
    - 条件选择
        - 通过树或者类似的特征组合模型去做最低熵的特征选择
            - ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8n2t44a2mj30im0bt0tz.jpg)
            - ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8n2v20wjbj30hs0dx0tq.jpg)
    
- 非线性编码
    - 核向量进行升维
    - 树模型的叶子结点的stack
    - 谱聚类/pca/svd等信息抽取编码
    - lda/EM等分布拟合表示

**离散特征常用方法**

- one-hot-encoder
- 分层编码
    - 有一定规律的类别数据，邮政编码，手机号等等
- 计数编码
    - 将类别特征用其对应的计数来代替,这对线性和非线性模型都有效
    - 对异常值比较敏感,特征取值有可能冲突
- 计数排名编码
    - 解决上述问题，以排名代替值
- Embedding
    - 对于基数(类别变量所有可能不同取值的个数)很大的离散特征，简单模型任意欠拟合,而复杂模型任意过拟合;对于独热编码,得到的特征矩阵太稀疏.对于高基数类别变量,有效方式是基于目标变量对类别特征进行编码,即有监督的编码方式,适用于分类和回归问题
- 类别特征之间交叉组合
    - 笛卡尔交叉
- 类别特征和数值特征之间交叉组合
    - 均值、中位数、标准差、最大值和最小值
    - 分位数、方差、vif值、分段冲量

#### 3.1.1 字典特征抽取

作用：对字典数据进行特征值化



#### 3.1.2 文本特征抽取

作用：对文本数据进行特征值化

- 预处理手段有哪些？

  - 将字符转化为小写
  - 分词
  - 去除无用字符
  - 繁体转中文
  - 去除停用词
  - 去除稀有词
  - 半角全角切换
  - 错词纠正
  - 关键词标记
    - TF-IDF
    - LDA
    - LSA
  - 提取词根
  - 词干提取
  - 标点符号编码
  - 文档特征
  - 实体插入和提取
  - 文本向量化
    - word2vec
    - glove
    - bert
  - 文本相似性

- 如何做样本构造？

  - 按标点切分
  - 按句切分
  - 对话session切分
  - 按文章切分
  - 按场景切分

- 分词过程中会考虑哪些方面？

  - 词性标注
  - 词形还原和词干提取
    - 词形还原为了通用性特征的提取
    - 词干提取为了去除干扰词把训练注意力集中在关键词上，同时提高速度；缺点是不一定词干代表完整句义

- 文本中的统计信息一般有哪些？

  - 直接统计值：
    - 文本的长度
    - 单词个数
    - 数字个数
    - 字母个数
    - 大小写单词个数
    - 大小写字母个数
    - 标点符号个数
    - 特殊字符个数
    - 数字占比
    - 字母占比
    - 特殊字符占比
    - 不同词性个数    
  - 直接统计值的统计信息：
    - 最小最大均值方差标准差
    - 分位数，最早/最晚出现位置

- 直接对文本特征进行整理手段有哪些？   

  - N-Gram模型
    - 将文本转换为连续序列，扩充样本特征
    - 连续语意的提取
  - TF-IDF
    - 权重评分，去除掉一些低重要性的词，比如每篇文章都出现的"的"，"了"
  - LDA
    - 主题抽取，用狄利克雷分布去拟合出文章和主题之间的关系
  - 相似度
    - 余弦相似度
    - Jaccard相似度
      - 共现性
    - Levenshtein(编辑距离)
      - 文本近似程度
    - 海林格距离
      - 用来衡量概率分布之间的相似性
    - JSD
      - 衡量prob1 和 prob2两个分布的相似程度
  - 向量化
    - word2vec
    - glove
    - bert

  

##### 3.1.2.1 one-hot 



##### 3.1.2.2 TF-IDF

TF-IDF的主要思想是：如果某个词或短语在一篇文章中出现的概率高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。

TF-IDF作用：用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。

#### 3.1.3 异常点检测

**统计方法**

- 3∂原则
    - 数据需要服从正态分布
    - 只能解决一维问题：![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8m954lh5tj301h00gdfl.jpg)
- 基于正态分布的离群点检测方法
    - 一元高斯分布校验：![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8m91basuwj306201h0sl.jpg)，如果概率值大小离群则代表为异常点
    - 多元高斯分布检测：
        - 假设 n 维的数据集合 ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8m9e4sjkoj303000it8l.jpg)，可以计算 n 维的均值向量![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8m9ewbb1cj304b00igli.jpg)
        - ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8m9fdr3xfj30140080sl.jpg)的协方差矩阵：![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8m9fly7rpj306g00ja9z.jpg)
        - 得到![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8m9gzmd1cj30bz01874b.jpg) 
    - ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8m92kshc2j30d6073dft.jpg)
- 马氏距离
    - 假设![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8m9kw2qf3j300900awec.jpg)是均值向量，其中S是协方差矩阵。
    - ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8m9kguzdgj307e00lmx3.jpg)
- ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8m9rdqiqjj300g00h0sl.jpg)统计检验
    - ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8m9ryphxxj304u00kmx2.jpg)
    - ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8m9sgjwk1j300d00awec.jpg)是a在第i维上的取值,![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8m9sljfhpj300g00e0sl.jpg)是所有对象在第 i 维的均值，n是维度
- 箱型图
    - IQR，\[Q1-3/2(Q3-Q1),Q3+3/2(Q3-Q1)]

**矩阵分解方法**

- PCA
    - 去除均值后的协方差矩阵对应的特征值和特征向量，按照特征值排序，topN个特征向量组成新的低维空间
    - 核心：在于组合原始的特征，使得新的原始数据在新的低维度空间中的方差更大，特征更有区分力
    - 问题是没有做到剔除，只是对空间上的表现进行了优化，尽可能的压缩异常点在新空间中作用
- SVD
    - 假设 dataMat 是一个 p 维的数据集合，有 N 个样本，它的协方差矩阵是 X。那么协方差矩阵就通过奇异值分解写成：![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8man1o3trj302h00hmx1.jpg)
    - 其中 P 是一个 (p,p) 维的正交矩阵，它的每一列都是 X 的特征向量。D 是一个 (p,p) 维的对角矩阵，包含了特征值 ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8manhjc7qj301n00ga9x.jpg)。
    - ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8mar6eb43j304300h746.jpg)可以认为是dataMat在主成分topj上的映射
    - 最后还需要拉回原空间：![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8mb1hmrmnj306w00i747.jpg)
    - 异常值分数（outlier score）：![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8maynk5wkj30a300mjrc.jpg) + ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8mayu64x7j305500mt8m.jpg)

**特征值和特征向量的本质是什么？**

- 一个特征向量可以看成 2 维平面上面的一条线，或者高维空间里面的一个超平面
- 特征向量所对应的特征值反映了这批数据在这个方向上的拉伸程度 

**矩阵乘法的实际意义？**

- 两个矩阵相乘的意义是将右边矩阵中的每一列列向量变换到左边矩阵中每一行行向量为基所表示的空间中去。
- 矩阵点乘向量的意义是将右边的向量变换到左边矩阵中每一行行向量为基所表示的空间中去。

**密度的离群点检测**

- 定义密度为到k个最近邻的平均距离的倒数。如果该距离小，则密度高，反之亦然。另一种密度定义是使用DBSCAN聚类算法使用的密度定义，即一个对象周围的密度等于该对象指定距离d内对象的个数。
    - 我们可以通过随机选择联通点，人为设置联通点附近最小半径a，半径内最小容忍点个数b，再考虑密度可达，形成蓝色方框内的正常数据区域，剩下的黄色区域内的点即为异常点。
- Local Outlier Factor算法
- 孤立森林:![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8mcoswixrj30iy0em0tb.jpg)
    - 经验1：每棵树的最大深度limit length=ceiling(log2(样本大小))
    - 经验2：树的个数在256棵以下
缺点：
    - 计算量大：o(n^2)
    - 需要人为选择阈值
    

**聚类的离群点检测**

- 一个对象是基于聚类的离群点，如果该对象不强属于任何簇，那么该对象属于离群点。
- 缺点也就是聚类的缺点，包括初始点对结果的影响，数据是否保持凸型对结果对影响，簇的个数的选择

**如何处理异常点？**

- 删除含有异常值的记录：直接将含有异常值的记录删除；
- 视为缺失值：将异常值视为缺失值，利用缺失值处理的方法进行处理；
- 平均值修正：可用前后两个观测值的平均值修正该异常值；
- 生成列新特征：category异常
- 不处理：直接在具有异常值的数据集上进行数据挖掘；


### 3.2 特征处理

特征处理即通过特定的统计方法（数学方法）将数据转换成算法要求的数据

![image-20210208161022295](https://gitee.com/zgf1366/pic_store/raw/master/img/20210208183307.png)

#### 3.2.1 归一化

特点：通过对原始数据进行变换把数据映射到(默认为[0,1])之间

公式：
$$
X^′= (x-min)/(max-min)
$$

$$
𝑋^′′=𝑋^′∗(𝑚𝑥−𝑚𝑖)+𝑚𝑖
$$

注：作用于每一列，max为一列的最大值，min为一列的最小值,那么X’’为最终结果，mx，mi分别为指定区间值默认mx为1,mi为0

![image-20210208161248859](https://gitee.com/zgf1366/pic_store/raw/master/img/20210208161249.png)

注意在特定场景下最大值最小值是变化的，另外，最大值与最小值非常容易受异常点影响，所以这种方法鲁棒性较差，只适合传统精确小数据场景。

#### 3.2.2 标准化

特点：通过对原始数据进行变换把数据变换到均值为0,方差为1范围内



![image-20210208161551990](https://gitee.com/zgf1366/pic_store/raw/master/img/20210208161552.png)

对于归一化来说：如果出现异常点，影响了最大值和最小值，那么结果显然会发生改变

对于标准化来说：如果出现异常点，由于具有一定数据量，少量的异常点对于平均值的影响并不大，从而方差改变较小。

**标准化总结**

在已有样本足够多的情况下比较稳定，适合现代嘈杂大数据场景。

**为什么需要对数据进行变换？**

- 避免异常点：比如对连续变量进行份桶离散化
- 可解释性或者需要连续输出：比如评分卡模型中的iv+woe
- 使得原始数据的信息量更大：比如log/sqrt变换

**归一化和标准化之间的关系？**

- 归一化(max-min)
  - 缩放仅仅跟最大、最小值的差别有关，只是一个去量纲的过程

- 标准化(z-score)
  - 缩放和所有点都相关，数据相对分布不会改变，集中的数据标准化后依旧集中

- 作用
  - 解决部分模型由于数据值域不同对模型产生的影响，尤其是距离模型
  - 更快的收敛
  - 去量纲化
  - 避免数值计算溢出

- 总结
  - 异常点角度：特征数据上下限明显异常的时候使用标准化方法，简单归一化会造成数据差异模糊，整体方差下降
  - 分布角度：使用标准化之前，要求数据需要近似满足高斯分布，不然会改变数据的分布，尤其是对数据分布有强假设的情况下
  - 上线变动角度：归一化在上线的时候需要考虑上下约束届是否需要变动，标准化则不需要考虑变动
  - 值域范围角度：归一化对数据范围约定较为固定，而标准化的输出上下届则不定
  - 模型角度：一般涉及距离计算，协方差计算，数据满足高斯分布的情况下用标准化，其他归一化或其他变换

#### 3.2.3 缺失值

删除 - 如果每列或者行数据缺失值达到一定的比例，建议放弃整行或者整列

插补 - 可以通过缺失值每行或者每列的平均值、中位数来填充

**是不是一定需要对缺失值处理？**

当缺失值占比在可接受的范围以内的时候才需要进行填充，如果缺失值大于50%以上的时候，可以选择进行二分化，如果缺失值大于80%可以完整删除该列而不是强行去填充

**直接填充方法有哪些？**

- 均值
- 中位数
- 众数
- 分位数

**模型插值方法有哪些？及方法的问题**

- 有效性存疑，取决于特征列数
  - 生成的插值来源于其他列的特征，是不是意味着插值的结果已经是和其他列的组合高相关

**如何直接离散化？**

- 离散特征新增缺失的category

**hold位填充方法有哪些？**

把全部结果都embedding化，对空值或者缺失值按照一定规则生成若干个hold位，以hold位的向量结果作为缺失值的结果
    - 可以参考YouTube中的新商品向量生成逻辑
        - bert中的\[UNK]向量，\[unused]向量

**怎么理解分布补全？**

如果我们能在原始数据上发现明显规律，比如整体数据满足高维多元高斯分布，则可以通过未知列补全缺失列的值

**random方法**

在缺失量特别少(通常认为小于1%)的时候，可以随机生成

**总结**

- 实际机器学习工程中，直接删除、众数填充和直接离散化方法用的最多
  - 快速
  - 对原始数据的前提假设最少，也不会影响到非缺失列
- 在深度学习中，hold位填充方法用的最多
  - 在大量数据的拟合条件下，能保证这些未知数据处的向量也能得到收敛
  - 而且通过随机构造的特性，保证了缺失处的\[UNK]向量，\[unused]向量的通配性

### 3.3 特征选择

#### 3.3.1 特征选择原因

- 冗余：部分特征的相关度高，容易消耗计算性能
- 噪声：部分特征对预测结果有负影响
- 耗时：特征个数越多，分析特征、训练模型所需的时间就越长。
- 过拟合：特征个数越多，容易引起“维度灾难”，模型也会越复杂，其推广能力会下降。    
- 共线性：单因子对目标的作用被稀释，解释力下降

#### 3.3.2 特征选择是什么

特征选择就是单纯地从提取到的所有特征中选择部分特征作为训练集特征，特征在选择前和选择后可以改变值、也不改变值，但是选择后的特征维数肯定比选择前小，毕竟我们只选择了其中的一部分特征。

主要方法（三大武器）：

Filter(过滤式):VarianceThreshold

Embedded(嵌入式)：正则化、决策树

Wrapper(包裹式)

#### 3.3.3 从哪些方面可以做特征选择？

- 方差，是的feature内的方向更大，对目标区分度提高更高贡献
  - 移除低方差特征
    - 移除低方差特征是指移除那些方差低于某个阈值，即特征值变动幅度小于某个范围的特征，这一部分特征的区分度较差，我们进行移除
  - 考虑有值数据中的占比，异常数据的占比，正常范围数据过少的数据也可以移除

- 相关性，与区分目标相关的特征才有意义
  - 单变量特征选择：单变量特征是基于单一变量和目标y之间的关系，通过计算某个能够度量特征重要性的指标，然后选出重要性Top的K个特征。但是这种方式有一个缺点就是忽略了特征组合的情况
    - 皮尔森相关系数:![](https://gitee.com/zgf1366/pic_store/raw/master/img/20210208192254.jpeg)
    - Fisher得分:

![](https://gitee.com/zgf1366/pic_store/raw/master/img/20210208192322.jpeg)



- 假设检验
  - 卡方检验
  - ANOVA

- 熵检验
  - 互信息熵
    - 度量两个变量之间的相关性,互信息越大表明两个变量相关性越高;互信息为0,两个变量越独立
  - KL散度
  - 相对熵

### 3.4 数据平衡

**为什么要对数据进行采样平衡**

- 下采样：克服高维特征以及大量数据导致的问题,有助于降低成本,缩短时间甚至提升效果
- 上采样：均衡正负样本的数据，避免数据不平衡导致分类器对正负样本的有偏训练
  - 比如99%为正样本，1%为负样本，如果分类器把所以样本预测为正样本则准确率高达99%，显然不符合实际情况

**是否一定需要对原始数据进行采样平衡**

否。

- 采样前后会对原始数据的分布进行改变，可能导致泛化能力大大下降
- 采样有一定概率会造成过拟合，当原始数据过少而采样量又很大当时候，造成大量数据被重复，造成模型训练的结果有一定的过拟合

**有哪些常见的采样方法？**

- 随机采样
  - 无放回的简单抽样：每条样本被采到的概率相等且都为1/N
  - 有放回的简单抽样：每条样本可能多次被选中
  - 上采样：即合理地增加少数类的样本
  - 下采样：欠抽样技术是将数据从原始数据集中移除
  - 平衡采样：考虑正负样本比
  - 分层采样：通过某一些feature对数据进行切分，按照切分后的占比分别进行采样
  - 整体采样：先将数据集T中的数据分组成G个互斥的簇,然后再从G个簇中简单随机采样s个簇作为样本集
- 合成采样
  相对于采样随机的方法进行上采样, 还有两种比较流行的上采样的改进方式： 
    - SMOTE
      - x_new = x + rand(0,1) * (x′−x)
      - **带来新样本的同时有可能造成不同类别样本之间的重合**
      - Borderline-SMOTE为了解决上面的问题，在x_new生成之前，会先判断x这个点是否周围都是同类别的点
    - ADASYN
      - 同上，也是在构造样本点的过程中考虑了正负样本比
- 平衡欠采样        
  - EasyEnsemble，利用模型融合的方法（Ensemble）
    - 少样本不变，多样本拆分成N份，分别组合进行模型训练后进行模型融合
  - BalanceCascade，利用模型融合的方法（Boost）
    - 每次剔除预测正确的多数样本，加入新的未预测的多数样本
  - NearMiss
    - 选择离各种情况下的少数样本位置最远的多数样本进行训练                

**能否避免采样？**

可以通过修改模型训练中的loss权重，比如逻辑回归中进行case_weight的调整，adaboost中对样本错分权重的改变等等。

**怎么用采样方法？**

尽量避免使用合成采样的方式去做数据填充，总结如下：

- 由于项目中时间的充裕问题，填充的结果往往是正负样本交叠且无感知的，会干扰分类器
- 通常我们引入的特征不仅仅是连续变量，在分类变量上合成采样表现并不优秀
- 合成采样往往无法与后序模型进行结合使用，比如随机采样可以引入模型交叉，比如平衡欠采样可以引入模型融合